{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sJwTX78T6cnq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3349394-8d13-46a8-f386-92a64c0c41b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:46,888]\u001b[0m A new study created in memory with name: lightgbm\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
            "[LightGBM] [Warning] min_gain_to_split is set=8.532899149230442, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.532899149230442\n",
            "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.7\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=0.6 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:48,469]\u001b[0m Trial 0 finished with value: 850025325.7283984 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.1029805430313656, 'num_leaves': 1760, 'max_depth': 23, 'lambda_l1': 50, 'lambda_l2': 75, 'min_gain_to_split': 8.532899149230442, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.7, 'min_data_per_groups': 74}. Best is trial 0 with value: 850025325.7283984.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[680]\tvalid_0's rmse: 29155.2\n",
            "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
            "[LightGBM] [Warning] min_gain_to_split is set=4.051592564686907, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.051592564686907\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:51,837]\u001b[0m Trial 1 finished with value: 808212359.0774509 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.16926232578759773, 'num_leaves': 2800, 'max_depth': 59, 'lambda_l1': 5, 'lambda_l2': 0, 'min_gain_to_split': 4.051592564686907, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.5, 'min_data_per_groups': 39}. Best is trial 1 with value: 808212359.0774509.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[43]\tvalid_0's rmse: 28429.1\n",
            "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
            "[LightGBM] [Warning] min_gain_to_split is set=3.1752223871790903, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.1752223871790903\n",
            "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.9 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:52,607]\u001b[0m Trial 2 finished with value: 812943515.9793749 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.17330069864250813, 'num_leaves': 2340, 'max_depth': 24, 'lambda_l1': 30, 'lambda_l2': 60, 'min_gain_to_split': 3.1752223871790903, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.8, 'min_data_per_groups': 94}. Best is trial 1 with value: 808212359.0774509.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[170]\tvalid_0's rmse: 28512.2\n",
            "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
            "[LightGBM] [Warning] min_gain_to_split is set=3.0631499585597903, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.0631499585597903\n",
            "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1499]\tvalid_0's rmse: 28182.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:56,427]\u001b[0m Trial 3 finished with value: 794245034.0183307 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.017684339539257493, 'num_leaves': 120, 'max_depth': 34, 'lambda_l1': 70, 'lambda_l2': 70, 'min_gain_to_split': 3.0631499585597903, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.5, 'min_data_per_groups': 45}. Best is trial 3 with value: 794245034.0183307.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
            "[LightGBM] [Warning] min_gain_to_split is set=3.673022488126125, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.673022488126125\n",
            "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=0.4 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=0.7 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:57,312]\u001b[0m Trial 4 finished with value: 930135052.1832384 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.4, 'subsample': 0.7, 'learning_rate': 0.20514584099913596, 'num_leaves': 2980, 'max_depth': 29, 'lambda_l1': 70, 'lambda_l2': 95, 'min_gain_to_split': 3.673022488126125, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.9, 'min_data_per_groups': 79}. Best is trial 3 with value: 794245034.0183307.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:04:57,354]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[376]\tvalid_0's rmse: 30498.1\n",
            "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.2122690949683612, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.2122690949683612\n",
            "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=0.5 will be ignored. Current value: bagging_fraction=0.2\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:58,732]\u001b[0m Trial 6 finished with value: 907419441.4837323 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.23694080769245046, 'num_leaves': 2160, 'max_depth': 75, 'lambda_l1': 45, 'lambda_l2': 95, 'min_gain_to_split': 4.977464274689595, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9, 'min_data_per_groups': 77}. Best is trial 3 with value: 794245034.0183307.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[316]\tvalid_0's rmse: 30123.4\n",
            "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
            "[LightGBM] [Warning] min_gain_to_split is set=10.814441149776977, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.814441149776977\n",
            "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=0.9 will be ignored. Current value: feature_fraction=0.7\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:59,288]\u001b[0m Trial 7 finished with value: 846860169.5800471 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.23004073848984968, 'num_leaves': 2120, 'max_depth': 22, 'lambda_l1': 25, 'lambda_l2': 35, 'min_gain_to_split': 10.814441149776977, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.7, 'min_data_per_groups': 86}. Best is trial 3 with value: 794245034.0183307.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[61]\tvalid_0's rmse: 29100.9\n",
            "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
            "[LightGBM] [Warning] min_gain_to_split is set=11.337307834790998, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.337307834790998\n",
            "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=0.4 will be ignored. Current value: feature_fraction=0.7\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=0.4 will be ignored. Current value: bagging_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:59,740]\u001b[0m Trial 8 finished with value: 859537277.6015306 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.2678309206541556, 'num_leaves': 1720, 'max_depth': 29, 'lambda_l1': 95, 'lambda_l2': 10, 'min_gain_to_split': 11.337307834790998, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.7, 'min_data_per_groups': 2}. Best is trial 3 with value: 794245034.0183307.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:04:59,774]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:04:59,839]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:04:59,917]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[54]\tvalid_0's rmse: 29317.9\n",
            "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
            "[LightGBM] [Warning] min_gain_to_split is set=11.333191566986898, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.333191566986898\n",
            "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=0.9 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:04:59,994]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,067]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,147]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,245]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,339]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,423]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,519]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,606]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,697]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,790]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,897]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:00,996]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:01,098]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:01,186]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:01,314]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:01,411]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:01,507]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:01,615]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:01,734]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:05,842]\u001b[0m Trial 31 finished with value: 853854774.0806085 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.21364663081300395, 'num_leaves': 2280, 'max_depth': 20, 'lambda_l1': 25, 'lambda_l2': 35, 'min_gain_to_split': 5.496195944697495, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.7, 'min_data_per_groups': 88}. Best is trial 3 with value: 794245034.0183307.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[126]\tvalid_0's rmse: 29220.8\n",
            "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
            "[LightGBM] [Warning] min_gain_to_split is set=8.704204754265538, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.704204754265538\n",
            "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.9 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:06,100]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:06,201]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:06,921]\u001b[0m Trial 34 finished with value: 814667495.6535538 and parameters: {'n_estimators': 20000, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.14845353467486364, 'num_leaves': 2940, 'max_depth': 23, 'lambda_l1': 15, 'lambda_l2': 0, 'min_gain_to_split': 4.581064023902234, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.7, 'min_data_per_groups': 81}. Best is trial 3 with value: 794245034.0183307.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:07,039]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[53]\tvalid_0's rmse: 28542.4\n",
            "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
            "[LightGBM] [Warning] min_gain_to_split is set=4.493355407752172, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.493355407752172\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:07,146]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:07,252]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:07,870]\u001b[0m Trial 38 finished with value: 782499428.8953199 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.24489617225435922, 'num_leaves': 2800, 'max_depth': 17, 'lambda_l1': 70, 'lambda_l2': 5, 'min_gain_to_split': 3.318183082127133, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001, 'min_data_per_groups': 71}. Best is trial 38 with value: 782499428.8953199.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:07,983]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[51]\tvalid_0's rmse: 27973.2\n",
            "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
            "[LightGBM] [Warning] min_gain_to_split is set=3.2654379265494455, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.2654379265494455\n",
            "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=0.4 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=0.4 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:08,085]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:08,361]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 64.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:08,452]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:09,058]\u001b[0m Trial 43 finished with value: 777931457.2987448 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.247984272795805, 'num_leaves': 2480, 'max_depth': 24, 'lambda_l1': 75, 'lambda_l2': 0, 'min_gain_to_split': 3.160242356640873, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.7, 'min_data_per_groups': 69}. Best is trial 43 with value: 777931457.2987448.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[19]\tvalid_0's rmse: 27891.4\n",
            "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
            "[LightGBM] [Warning] min_gain_to_split is set=3.246366260955959, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.246366260955959\n",
            "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:09,735]\u001b[0m Trial 44 finished with value: 824237709.4418552 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.24451379549708505, 'num_leaves': 2400, 'max_depth': 28, 'lambda_l1': 75, 'lambda_l2': 10, 'min_gain_to_split': 3.246366260955959, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.5, 'min_data_per_groups': 44}. Best is trial 43 with value: 777931457.2987448.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:09,843]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[86]\tvalid_0's rmse: 28709.5\n",
            "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
            "[LightGBM] [Warning] min_gain_to_split is set=2.016854701267447, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.016854701267447\n",
            "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.5\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:10,330]\u001b[0m Trial 46 finished with value: 823267149.9444742 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.2600871057655526, 'num_leaves': 220, 'max_depth': 17, 'lambda_l1': 90, 'lambda_l2': 5, 'min_gain_to_split': 0.8330052369698073, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001, 'min_data_per_groups': 59}. Best is trial 43 with value: 777931457.2987448.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[43]\tvalid_0's rmse: 28692.6\n",
            "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
            "[LightGBM] [Warning] min_gain_to_split is set=2.9288248148567515, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.9288248148567515\n",
            "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:11,006]\u001b[0m Trial 47 finished with value: 849572619.6934067 and parameters: {'n_estimators': 20000, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.23975455867196552, 'num_leaves': 1780, 'max_depth': 54, 'lambda_l1': 75, 'lambda_l2': 10, 'min_gain_to_split': 2.9288248148567515, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.7, 'min_data_per_groups': 70}. Best is trial 43 with value: 777931457.2987448.\u001b[0m\n",
            "\u001b[32m[I 2023-04-17 03:05:11,108]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[98]\tvalid_0's rmse: 29147.4\n",
            "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
            "[LightGBM] [Warning] min_gain_to_split is set=5.226829291920923, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.226829291920923\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.4\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=0.8 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-17 03:05:11,214]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tBest value (rmse): 777931457.29874\n",
            "\tBest params:\n",
            "\t\tn_estimators: 20000\n",
            "\t\tcolsample_bytree: 0.7\n",
            "\t\tsubsample: 0.6\n",
            "\t\tlearning_rate: 0.247984272795805\n",
            "\t\tnum_leaves: 2480\n",
            "\t\tmax_depth: 24\n",
            "\t\tlambda_l1: 75\n",
            "\t\tlambda_l2: 0\n",
            "\t\tmin_gain_to_split: 3.160242356640873\n",
            "\t\tbagging_fraction: 0.9\n",
            "\t\tbagging_freq: 1\n",
            "\t\tfeature_fraction: 0.7\n",
            "\t\tmin_data_per_groups: 69\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"3c9b1f61-f79a-474f-b74a-423e10a242e1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3c9b1f61-f79a-474f-b74a-423e10a242e1\")) {                    Plotly.newPlot(                        \"3c9b1f61-f79a-474f-b74a-423e10a242e1\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"y\":[850025325.7283984,808212359.0774509,808212359.0774509,794245034.0183307,794245034.0183307,794245034.0183307,794245034.0183307,794245034.0183307,794245034.0183307,794245034.0183307,782499428.8953199,777931457.2987448,777931457.2987448,777931457.2987448,777931457.2987448],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3c9b1f61-f79a-474f-b74a-423e10a242e1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"ccebf916-560f-4edc-b9f8-a3740acc191a\" class=\"plotly-graph-div\" style=\"height:525px; width:3900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ccebf916-560f-4edc-b9f8-a3740acc191a\")) {                    Plotly.newPlot(                        \"ccebf916-560f-4edc-b9f8-a3740acc191a\",                        [{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":true},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.30000000000000004,0.8,0.9,0.5,0.30000000000000004,0.9,0.9,0.5,0.9,0.9,0.6000000000000001,0.9,0.6000000000000001,0.8,0.6000000000000001],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.8,0.6,0.9,0.7,0.4,0.3,0.9,0.4,0.9,1.0,0.4,0.7,0.7,0.7,0.5],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.7,0.5,0.8,0.5,0.9,0.9,0.7,0.7,0.7,0.7,0.6000000000000001,0.7,0.5,0.6000000000000001,0.7],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[50,5,30,70,70,45,25,95,25,15,70,75,75,90,75],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[75,0,60,70,95,95,35,10,35,0,5,0,10,5,10],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.1029805430313656,0.16926232578759773,0.17330069864250813,0.017684339539257493,0.20514584099913596,0.23694080769245046,0.23004073848984968,0.2678309206541556,0.21364663081300395,0.14845353467486364,0.24489617225435922,0.247984272795805,0.24451379549708505,0.2600871057655526,0.23975455867196552],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[23,59,24,34,29,75,22,29,20,23,17,24,28,17,54],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[74,39,94,45,79,77,86,2,88,81,71,69,44,59,70],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[8.532899149230442,4.051592564686907,3.1752223871790903,3.0631499585597903,3.673022488126125,4.977464274689595,10.814441149776977,11.337307834790998,5.496195944697495,4.581064023902234,3.318183082127133,3.160242356640873,3.246366260955959,0.8330052369698073,2.9288248148567515],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x10\",\"yaxis\":\"y10\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[20000,20000,20000,20000,20000,20000,20000,20000,20000,20000,20000,20000,20000,20000,20000],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x11\",\"yaxis\":\"y11\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[1760,2800,2340,120,2980,2160,2120,1720,2280,2940,2800,2480,2400,220,1780],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x12\",\"yaxis\":\"y12\"},{\"marker\":{\"color\":[0,1,2,3,4,6,7,8,31,34,38,43,44,46,47],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.6,0.8,1.0,0.6,0.7,0.8,0.6,0.4,0.6,0.6,0.6,0.6,0.6,0.6,0.7],\"y\":[850025325.7283984,808212359.0774509,812943515.9793749,794245034.0183307,930135052.1832384,907419441.4837323,846860169.5800471,859537277.6015306,853854774.0806085,814667495.6535538,782499428.8953199,777931457.2987448,824237709.4418552,823267149.9444742,849572619.6934067],\"type\":\"scatter\",\"xaxis\":\"x13\",\"yaxis\":\"y13\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.06272189349112425],\"title\":{\"text\":\"bagging_fraction\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Objective Value\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.07810650887573964,0.1408284023668639],\"title\":{\"text\":\"bagging_freq\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.15621301775147928,0.21893491124260353],\"title\":{\"text\":\"colsample_bytree\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.23431952662721892,0.29704142011834317],\"title\":{\"text\":\"feature_fraction\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.31242603550295855,0.3751479289940828],\"title\":{\"text\":\"lambda_l1\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.39053254437869817,0.45325443786982245],\"title\":{\"text\":\"lambda_l2\"}},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.4686390532544378,0.531360946745562],\"title\":{\"text\":\"learning_rate\"}},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.5467455621301773,0.6094674556213016],\"title\":{\"text\":\"max_depth\"}},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.624852071005917,0.6875739644970412],\"title\":{\"text\":\"min_data_per_groups\"}},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.7029585798816567,0.7656804733727809],\"title\":{\"text\":\"min_gain_to_split\"}},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis11\":{\"anchor\":\"y11\",\"domain\":[0.7810650887573962,0.8437869822485204],\"title\":{\"text\":\"n_estimators\"}},\"yaxis11\":{\"anchor\":\"x11\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis12\":{\"anchor\":\"y12\",\"domain\":[0.8591715976331358,0.92189349112426],\"title\":{\"text\":\"num_leaves\"}},\"yaxis12\":{\"anchor\":\"x12\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis13\":{\"anchor\":\"y13\",\"domain\":[0.9372781065088754,0.9999999999999997],\"title\":{\"text\":\"subsample\"}},\"yaxis13\":{\"anchor\":\"x13\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"title\":{\"text\":\"Slice Plot\"},\"width\":3900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ccebf916-560f-4edc-b9f8-a3740acc191a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"06e7203d-7263-42ae-9d43-fc6250470444\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"06e7203d-7263-42ae-9d43-fc6250470444\")) {                    Plotly.newPlot(                        \"06e7203d-7263-42ae-9d43-fc6250470444\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"bagging_freq (CategoricalDistribution): 0.0<extra></extra>\",\"n_estimators (CategoricalDistribution): 0.0<extra></extra>\",\"lambda_l1 (IntDistribution): 0.008658560477815483<extra></extra>\",\"max_depth (IntDistribution): 0.015679302066958296<extra></extra>\",\"subsample (CategoricalDistribution): 0.029409709758438148<extra></extra>\",\"learning_rate (FloatDistribution): 0.03544361224924516<extra></extra>\",\"colsample_bytree (CategoricalDistribution): 0.03629788203655559<extra></extra>\",\"min_data_per_groups (IntDistribution): 0.03874078095457123<extra></extra>\",\"bagging_fraction (FloatDistribution): 0.04358570459829331<extra></extra>\",\"num_leaves (IntDistribution): 0.1254510103633254<extra></extra>\",\"lambda_l2 (IntDistribution): 0.1843949880420669<extra></extra>\",\"min_gain_to_split (FloatDistribution): 0.22845101129811896<extra></extra>\",\"feature_fraction (FloatDistribution): 0.2538874381546115<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"<0.01\",\"<0.01\",\"<0.01\",\"0.02\",\"0.03\",\"0.04\",\"0.04\",\"0.04\",\"0.04\",\"0.13\",\"0.18\",\"0.23\",\"0.25\"],\"textposition\":\"outside\",\"x\":[0.0,0.0,0.008658560477815483,0.015679302066958296,0.029409709758438148,0.03544361224924516,0.03629788203655559,0.03874078095457123,0.04358570459829331,0.1254510103633254,0.1843949880420669,0.22845101129811896,0.2538874381546115],\"y\":[\"bagging_freq\",\"n_estimators\",\"lambda_l1\",\"max_depth\",\"subsample\",\"learning_rate\",\"colsample_bytree\",\"min_data_per_groups\",\"bagging_fraction\",\"num_leaves\",\"lambda_l2\",\"min_gain_to_split\",\"feature_fraction\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('06e7203d-7263-42ae-9d43-fc6250470444');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optuna Price: 225337.30034241217\n",
            "Optuna Price: 182019.6523214714\n",
            "Optuna Price: 111352.21606774292\n",
            "Optuna Price: 66325.56311194341\n",
            "Optuna Price: 151272.80504644866\n",
            "Optuna Price: 346979.96954410255\n",
            "Optuna Price: 315074.5425273202\n",
            "Optuna Price: 146623.18295361853\n",
            "Optuna Price: 215871.43893933244\n",
            "Optuna Price: 215912.4565592424\n",
            "Optuna Price: 179227.20201527252\n",
            "Optuna Price: 80636.76889063501\n",
            "Optuna Price: 183350.28622159772\n",
            "Optuna Price: 316231.5072902837\n",
            "Optuna Price: 243178.67528713957\n",
            "Optuna Price: 109117.04577070524\n",
            "Optuna Price: 110324.31948691314\n",
            "Optuna Price: 113779.51182541635\n",
            "Optuna Price: 238683.56555092987\n",
            "Optuna Price: 119952.39492711765\n",
            "Optuna Price: 118924.975305371\n",
            "Optuna Price: 123200.95857740453\n",
            "Optuna Price: 275322.7634276986\n",
            "Optuna Price: 307252.02703249076\n",
            "Optuna Price: 102577.61861432229\n",
            "Optuna Price: 218139.89452493846\n",
            "Optuna Price: 139251.53452757892\n",
            "Optuna Price: 175445.78364563372\n",
            "Optuna Price: 515635.4439715337\n",
            "Optuna Price: 138877.07914641002\n",
            "Optuna Price: 111410.3434532526\n",
            "Optuna Price: 117674.02837903096\n",
            "Optuna Price: 127392.23353503323\n",
            "Optuna Price: 93251.27898302878\n",
            "Optuna Price: 133036.4597672854\n",
            "Optuna Price: 368434.2164981288\n",
            "Optuna Price: 128688.64641289257\n",
            "Optuna Price: 72928.34923295943\n",
            "Optuna Price: 256894.78706393176\n",
            "Optuna Price: 104323.9535634574\n",
            "Optuna Price: 134238.38572400183\n",
            "Optuna Price: 130208.11486038394\n",
            "Optuna Price: 95030.07325817097\n",
            "Optuna Price: 122135.03099671572\n",
            "Optuna Price: 180174.9358372744\n",
            "Optuna Price: 185619.7202227285\n",
            "Optuna Price: 139602.1561034377\n",
            "Optuna Price: 186118.02381432542\n",
            "Optuna Price: 279158.0872996133\n",
            "Optuna Price: 264658.55034457217\n",
            "Optuna Price: 108032.34940340386\n",
            "Optuna Price: 372397.83001726924\n",
            "Optuna Price: 110497.26517362041\n",
            "Optuna Price: 219187.13005807955\n",
            "Optuna Price: 225345.80505854622\n",
            "Optuna Price: 101067.44079786149\n",
            "Optuna Price: 120315.55525310595\n",
            "Optuna Price: 171826.42446331825\n",
            "Optuna Price: 124549.54467039833\n",
            "Optuna Price: 183004.9037330935\n",
            "Optuna Price: 166815.09891676743\n",
            "Optuna Price: 278270.9055908835\n",
            "Optuna Price: 85976.61930110033\n",
            "Optuna Price: 127183.47073509698\n",
            "Optuna Price: 165082.79851233165\n",
            "Optuna Price: 125480.7660822612\n",
            "Optuna Price: 137814.76158825663\n",
            "Optuna Price: 239235.5527159385\n",
            "Optuna Price: 146970.0397288523\n",
            "Optuna Price: 157553.27097065866\n",
            "Optuna Price: 167932.7338774866\n",
            "Optuna Price: 102744.1488364682\n",
            "Optuna Price: 384454.99528438016\n",
            "Optuna Price: 160359.95815004062\n",
            "Optuna Price: 152244.13321401415\n",
            "Optuna Price: 227069.4015575595\n",
            "Optuna Price: 174275.8728190361\n",
            "Optuna Price: 135354.3443216821\n",
            "Optuna Price: 393619.1634283439\n",
            "Optuna Price: 193693.35702621943\n",
            "Optuna Price: 179622.0730110074\n",
            "Optuna Price: 124938.05122327319\n",
            "Optuna Price: 139774.7586837524\n",
            "Optuna Price: 139580.70561387818\n",
            "Optuna Price: 172317.78545487014\n",
            "Optuna Price: 145409.88679334725\n",
            "Optuna Price: 161219.8495374084\n",
            "Optuna Price: 176452.2031089704\n",
            "Optuna Price: 183438.1201542428\n",
            "Optuna Price: 159542.4534601687\n",
            "Optuna Price: 194167.22317240565\n",
            "Optuna Price: 183088.23543401127\n",
            "Optuna Price: 106876.46961258701\n",
            "Optuna Price: 99585.63568753611\n",
            "Optuna Price: 117258.11833387363\n",
            "Optuna Price: 107025.07473019305\n",
            "Optuna Price: 109182.50514044854\n",
            "Optuna Price: 136878.99499112045\n",
            "Optuna Price: 130907.91478772051\n",
            "Optuna Price: 142283.08302744947\n",
            "Optuna Price: 154141.8494273091\n",
            "Optuna Price: 143340.541326899\n",
            "Optuna Price: 111177.96511863288\n",
            "Optuna Price: 134383.85900342\n",
            "Optuna Price: 127014.5228756442\n",
            "Optuna Price: 181259.6430401847\n",
            "Optuna Price: 176709.08115319425\n",
            "Optuna Price: 173979.93366024512\n",
            "Optuna Price: 164778.73194246428\n",
            "Optuna Price: 288206.12252156954\n",
            "Optuna Price: 140728.90518288664\n",
            "Optuna Price: 186309.75887318695\n",
            "Optuna Price: 140289.24873310246\n",
            "Optuna Price: 184875.3244717725\n",
            "Optuna Price: 224554.4435274974\n",
            "Optuna Price: 166937.21093668076\n",
            "Optuna Price: 252339.54426482876\n",
            "Optuna Price: 124831.81079821747\n",
            "Optuna Price: 186225.27572480516\n",
            "Optuna Price: 254410.86623783276\n",
            "Optuna Price: 140117.5523307832\n",
            "Optuna Price: 225384.0767396839\n",
            "Optuna Price: 290982.31646461756\n",
            "Optuna Price: 166517.65812818217\n",
            "Optuna Price: 187356.36475349707\n",
            "Optuna Price: 186191.56006278383\n",
            "Optuna Price: 352860.6523203466\n",
            "Optuna Price: 105815.77659332466\n",
            "Optuna Price: 193452.2160611835\n",
            "Optuna Price: 220864.39162367652\n",
            "Optuna Price: 278436.21665991313\n",
            "Optuna Price: 90969.20899741718\n",
            "Optuna Price: 140193.31178087837\n",
            "Optuna Price: 132274.6998902605\n",
            "Optuna Price: 103669.77203196003\n",
            "Optuna Price: 220816.72282882375\n",
            "Optuna Price: 453396.8394952635\n",
            "Optuna Price: 341754.47213012696\n",
            "Optuna Price: 250680.2953483352\n",
            "Optuna Price: 118753.42602870116\n",
            "Optuna Price: 113542.49751406698\n",
            "Optuna Price: 295611.2305359045\n",
            "Optuna Price: 179080.07549938172\n",
            "Optuna Price: 192825.01726739015\n",
            "Optuna Price: 96463.37285344028\n",
            "Optuna Price: 219576.34995802847\n",
            "Optuna Price: 106065.6239498315\n",
            "Optuna Price: 183806.04343967797\n",
            "Optuna Price: 231409.46622484992\n",
            "Optuna Price: 117028.67590612572\n",
            "Optuna Price: 162078.43452150305\n",
            "Optuna Price: 157060.66316118583\n",
            "Optuna Price: 123937.67327883457\n",
            "Optuna Price: 177590.30592659942\n",
            "Optuna Price: 182765.6092330008\n",
            "Optuna Price: 343803.4514522881\n",
            "Optuna Price: 85580.43905635335\n",
            "Optuna Price: 131051.75235695747\n",
            "Optuna Price: 81516.23796534806\n",
            "Optuna Price: 148571.79299014842\n",
            "Optuna Price: 65361.81454388248\n",
            "Optuna Price: 105078.09075958836\n",
            "Optuna Price: 151078.57497615585\n",
            "Optuna Price: 152265.64890713285\n",
            "Optuna Price: 115305.6469649005\n",
            "Optuna Price: 129741.27146313568\n",
            "Optuna Price: 179190.19703307128\n",
            "Optuna Price: 149487.14034843285\n",
            "Optuna Price: 130903.20115115527\n",
            "Optuna Price: 136428.20162176024\n",
            "Optuna Price: 238782.39921837408\n",
            "Optuna Price: 183961.60757602102\n",
            "Optuna Price: 223823.104541665\n",
            "Optuna Price: 284822.76146251813\n",
            "Optuna Price: 193285.99477083937\n",
            "Optuna Price: 141960.35789213612\n",
            "Optuna Price: 182398.2687451667\n",
            "Optuna Price: 198892.59864688618\n",
            "Optuna Price: 138581.99412308648\n",
            "Optuna Price: 158029.84606607995\n",
            "Optuna Price: 131371.0094689232\n",
            "Optuna Price: 187224.4237779606\n",
            "Optuna Price: 137577.53341826863\n",
            "Optuna Price: 127395.18412419072\n",
            "Optuna Price: 306563.4897695621\n",
            "Optuna Price: 130476.59322718694\n",
            "Optuna Price: 382364.3983890038\n",
            "Optuna Price: 301666.75018723233\n",
            "Optuna Price: 141788.40110209634\n",
            "Optuna Price: 124262.82842664243\n",
            "Optuna Price: 118636.3169470328\n",
            "Optuna Price: 152380.28643348164\n",
            "Optuna Price: 99360.70452934036\n",
            "Optuna Price: 214861.4653181998\n",
            "Optuna Price: 109238.12631633431\n",
            "Optuna Price: 277120.8558536778\n",
            "Optuna Price: 226530.04886445455\n",
            "Optuna Price: 143641.49325687307\n",
            "Optuna Price: 149652.9725331648\n",
            "Optuna Price: 71082.08289248224\n",
            "Optuna Price: 213530.58858475642\n",
            "Optuna Price: 268882.4000405357\n",
            "Optuna Price: 184855.56600891566\n",
            "Optuna Price: 185103.5832686081\n",
            "Optuna Price: 293328.84548814857\n",
            "Optuna Price: 119172.27279230424\n",
            "Optuna Price: 174094.17668022358\n",
            "Optuna Price: 266297.9670543974\n",
            "Optuna Price: 332997.1690176541\n",
            "Optuna Price: 227712.1835315266\n",
            "Optuna Price: 179537.52611906547\n",
            "Optuna Price: 119772.00467314987\n",
            "Optuna Price: 167354.35324878452\n",
            "Optuna Price: 115518.33326131599\n",
            "Optuna Price: 303905.1677975114\n",
            "Optuna Price: 255428.04514946666\n",
            "Optuna Price: 125324.35860932323\n",
            "Optuna Price: 84326.9441377876\n",
            "Optuna Price: 150577.00149083807\n",
            "Optuna Price: 83364.5331554942\n",
            "Optuna Price: 454942.7276326876\n",
            "Optuna Price: 119993.97905961273\n",
            "Optuna Price: 166166.7082777117\n",
            "Optuna Price: 158047.1500180943\n",
            "Optuna Price: 116449.88553486469\n",
            "Optuna Price: 128564.5477571516\n",
            "Optuna Price: 219986.51506459215\n",
            "Optuna Price: 161512.99147345425\n",
            "Optuna Price: 181398.1961308776\n",
            "Optuna Price: 172598.65051166393\n",
            "Optuna Price: 137247.8116513424\n",
            "Optuna Price: 193720.8133361853\n",
            "Optuna Price: 100502.42900709814\n",
            "Optuna Price: 135220.90491698432\n",
            "Optuna Price: 305160.87584404676\n",
            "Optuna Price: 120793.351911799\n",
            "Optuna Price: 267853.83573770686\n",
            "Optuna Price: 125161.07344856413\n",
            "Optuna Price: 120883.31516932364\n",
            "Optuna Price: 328341.58685619157\n",
            "Optuna Price: 289793.37671822804\n",
            "Optuna Price: 191996.58616129513\n",
            "Optuna Price: 137637.4390369329\n",
            "Optuna Price: 136498.61205860422\n",
            "Optuna Price: 112663.44293054112\n",
            "Optuna Price: 127218.7076433252\n",
            "Optuna Price: 152226.4396425152\n",
            "Optuna Price: 156574.46678819397\n",
            "Optuna Price: 161084.8005190985\n",
            "Optuna Price: 185836.59124476984\n",
            "Optuna Price: 124637.80304995344\n",
            "Optuna Price: 116317.46421924044\n",
            "Optuna Price: 181484.70072015785\n",
            "Optuna Price: 166018.58476757281\n",
            "Optuna Price: 111401.77462797915\n",
            "Optuna Price: 109093.86798812638\n",
            "Optuna Price: 182554.82253453878\n",
            "Optuna Price: 83337.0719301516\n",
            "Optuna Price: 315991.4226513123\n",
            "Optuna Price: 127271.76251251128\n",
            "Optuna Price: 235318.32012236226\n",
            "Optuna Price: 157024.10208003703\n",
            "Optuna Price: 218685.93986801963\n",
            "Optuna Price: 177815.23305550287\n",
            "Optuna Price: 107472.09481453779\n",
            "Optuna Price: 190662.36165805734\n",
            "Optuna Price: 135431.5198884766\n",
            "Optuna Price: 169756.2918438614\n",
            "Optuna Price: 146238.78068325832\n",
            "Optuna Price: 99851.66680389445\n",
            "Optuna Price: 187748.25626089823\n",
            "Optuna Price: 188289.50034597237\n",
            "Optuna Price: 73643.35415145993\n",
            "Optuna Price: 114573.37341740745\n",
            "Optuna Price: 179278.7928810692\n",
            "Optuna Price: 106928.075704367\n",
            "Optuna Price: 128931.82511385891\n",
            "Optuna Price: 129909.13805826708\n",
            "Optuna Price: 186555.84552159984\n",
            "Optuna Price: 139638.40627959406\n",
            "Optuna Price: 130306.4157517088\n",
            "Optuna Price: 133239.31783771835\n",
            "Optuna Price: 127358.3838335146\n",
            "Optuna Price: 152949.5866743998\n",
            "Optuna Price: 261808.46674113348\n",
            "Optuna Price: 249760.55629367757\n",
            "Optuna Price: 119734.36106948028\n",
            "Optuna Price: 92799.16472364536\n",
            "Optuna Price: 249216.68447205552\n",
            "Optuna Price: 105491.54174511561\n",
            "Optuna Price: 92149.79255955151\n",
            "Optuna Price: 278159.08034658316\n",
            "Optuna Price: 158975.74483093584\n",
            "Optuna Price: 95369.65494769487\n",
            "Optuna Price: 173110.2207683214\n",
            "Optuna Price: 222116.85316101357\n",
            "Optuna Price: 179602.37689216036\n",
            "Optuna Price: 198514.6159515816\n",
            "Optuna Price: 156275.8147156205\n",
            "Optuna Price: 122742.24368649935\n",
            "Optuna Price: 151531.76027088\n",
            "Optuna Price: 132736.19325313045\n",
            "Optuna Price: 148576.86426567132\n",
            "Optuna Price: 152621.62842888047\n",
            "Optuna Price: 128023.90924783534\n",
            "Optuna Price: 209099.98923691193\n",
            "Optuna Price: 137549.25902660147\n",
            "Optuna Price: 175074.729396478\n",
            "Optuna Price: 131981.590104657\n",
            "Optuna Price: 173342.08631918512\n",
            "Optuna Price: 152537.8945434997\n",
            "Optuna Price: 132806.31712773943\n",
            "Optuna Price: 104070.61042996182\n",
            "Optuna Price: 219840.92178194807\n",
            "Optuna Price: 151962.845708644\n",
            "Optuna Price: 72473.50577994502\n",
            "Optuna Price: 241597.33937477702\n",
            "Optuna Price: 184724.99194790504\n",
            "Optuna Price: 204591.77359667994\n",
            "Optuna Price: 158693.70706812295\n",
            "Optuna Price: 171659.93360557954\n",
            "Optuna Price: 155534.15582674096\n",
            "Optuna Price: 153510.70764630113\n",
            "Optuna Price: 240458.7154132727\n",
            "Optuna Price: 146814.67420720478\n",
            "Optuna Price: 398707.5669852403\n",
            "Optuna Price: 161206.17379866602\n",
            "Optuna Price: 270092.13813294267\n",
            "Optuna Price: 132384.15883023205\n",
            "Optuna Price: 106964.07848323471\n",
            "Optuna Price: 126452.39516773589\n",
            "Optuna Price: 265698.2776199279\n",
            "Optuna Price: 237846.04276277716\n",
            "Optuna Price: 283603.69772354176\n",
            "Optuna Price: 170863.865107078\n",
            "Optuna Price: 145936.23509368108\n",
            "Optuna Price: 146838.50670849584\n",
            "Optuna Price: 102724.34035638683\n",
            "Optuna Price: 282566.57714851806\n",
            "Optuna Price: 163857.60492923541\n",
            "Optuna Price: 203864.56603515486\n",
            "Optuna Price: 271966.83666393807\n",
            "Optuna Price: 76885.63510761186\n",
            "Optuna Price: 287080.68055189284\n",
            "Optuna Price: 93631.45055602989\n",
            "Optuna Price: 151428.49290044833\n",
            "Optuna Price: 151826.43094946226\n",
            "Optuna Price: 147359.07626351353\n",
            "Optuna Price: 275053.2357173641\n",
            "Optuna Price: 113291.26840801435\n",
            "Optuna Price: 187860.29435441268\n",
            "Optuna Price: 148476.41390400802\n",
            "Optuna Price: 339848.85390784574\n",
            "Optuna Price: 138540.9423363758\n",
            "Optuna Price: 142070.66435128052\n",
            "Optuna Price: 147090.43945793572\n",
            "Optuna Price: 184524.51299796323\n",
            "Optuna Price: 173143.28988801912\n",
            "Optuna Price: 96419.0705308366\n",
            "Optuna Price: 283274.43964726164\n",
            "Optuna Price: 230223.19914484248\n",
            "Optuna Price: 185232.7563575989\n",
            "Optuna Price: 142608.9213560624\n",
            "Optuna Price: 232129.79576598277\n",
            "Optuna Price: 186084.32179779734\n",
            "Optuna Price: 285602.1820970005\n",
            "Optuna Price: 157985.73743873875\n",
            "Optuna Price: 159992.40986871504\n",
            "Optuna Price: 199300.83009228052\n",
            "Optuna Price: 146161.92285983666\n",
            "Optuna Price: 136460.86718926663\n",
            "Optuna Price: 163701.51215838097\n",
            "Optuna Price: 225078.60454884963\n",
            "Optuna Price: 204891.12696000494\n",
            "Optuna Price: 267291.598579997\n",
            "Optuna Price: 225678.44856660382\n",
            "Optuna Price: 105719.8419277013\n",
            "Optuna Price: 109604.65336808629\n",
            "Optuna Price: 146944.08230155642\n",
            "Optuna Price: 409323.85619812907\n",
            "Optuna Price: 186998.30929983623\n",
            "Optuna Price: 70711.63779451206\n",
            "Optuna Price: 335509.19218505104\n",
            "Optuna Price: 160873.32948713336\n",
            "Optuna Price: 97909.61565781232\n",
            "Optuna Price: 247321.8623380716\n",
            "Optuna Price: 172976.91586128218\n",
            "Optuna Price: 461050.99335472996\n",
            "Optuna Price: 155255.9942593605\n",
            "Optuna Price: 87235.1192778402\n",
            "Optuna Price: 314006.56943685055\n",
            "Optuna Price: 161445.67832556454\n",
            "Optuna Price: 178941.83009752032\n",
            "Optuna Price: 177302.60599832892\n",
            "Optuna Price: 163334.92332988916\n",
            "Optuna Price: 140620.71484739592\n",
            "Optuna Price: 91311.66481090018\n",
            "Optuna Price: 281487.3668011248\n",
            "Optuna Price: 138254.84832562038\n",
            "Optuna Price: 325368.15082652203\n",
            "Optuna Price: 242785.1590676553\n",
            "Optuna Price: 229493.35702296847\n",
            "Optuna Price: 292840.4922258471\n",
            "Optuna Price: 278174.7334198644\n",
            "Optuna Price: 170132.12646806164\n",
            "Optuna Price: 194603.44456406156\n",
            "Optuna Price: 89959.01514462239\n",
            "Optuna Price: 140403.27702146195\n",
            "Optuna Price: 195525.02501705012\n",
            "Optuna Price: 172767.7528241515\n",
            "Optuna Price: 136114.63758471917\n",
            "Optuna Price: 358318.26372351346\n",
            "Optuna Price: 194927.43281870816\n",
            "Optuna Price: 130541.97105722167\n",
            "Optuna Price: 67624.65597170425\n",
            "Optuna Price: 152876.38838976095\n",
            "Optuna Price: 148477.933290125\n",
            "Optuna Price: 74297.12679040883\n",
            "Optuna Price: 143085.7393086483\n",
            "Optuna Price: 267858.7352496134\n",
            "Optuna Price: 79581.70463112491\n",
            "Optuna Price: 118456.44640779101\n",
            "Optuna Price: 100531.68288897106\n",
            "Optuna Price: 121852.49709338193\n",
            "Optuna Price: 314455.55458816397\n",
            "Optuna Price: 232992.09682737815\n",
            "Optuna Price: 329863.78135601233\n",
            "Optuna Price: 201185.15522329067\n",
            "Optuna Price: 181373.32561038373\n",
            "Optuna Price: 60968.70847304139\n",
            "Optuna Price: 181258.20771764277\n",
            "Optuna Price: 118864.788818089\n",
            "Optuna Price: 346527.18789021194\n",
            "Optuna Price: 240205.4416149423\n",
            "Optuna Price: 260830.69029435675\n",
            "Optuna Price: 161942.01451068738\n",
            "Optuna Price: 193097.93611418043\n",
            "Optuna Price: 257928.77859366822\n"
          ]
        }
      ],
      "source": [
        "#!pip install shap optuna\n",
        "#from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgbm\n",
        "import shap\n",
        "\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from optuna.integration import LightGBMPruningCallback\n",
        "from google.colab import files\n",
        "\n",
        "#Reading the csv data into a variable. CSV was stored on Google Drive.\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Project/train.csv\")\n",
        "\n",
        "#Removing the non-number columns from df. Storing all but last columns in x, last column in y\n",
        "df_int = df._get_numeric_data()\n",
        "x=df_int.drop(\"SalePrice\",axis=1)\n",
        "y=df_int.SalePrice\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
        "\n",
        "#Tuning the hyperparameters with Optuna\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Objective function to be minimized.\n",
        "    \"\"\"\n",
        "    param = {\n",
        "        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
        "        'metric': 'rmse',\n",
        "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [20000]),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 10, 100),\n",
        "        #\"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
        "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
        "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
        "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
        "        \"bagging_fraction\": trial.suggest_float(\n",
        "            \"bagging_fraction\", 0.2, 0.9, step=0.1\n",
        "        ),\n",
        "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
        "        \"feature_fraction\": trial.suggest_float(\n",
        "            \"feature_fraction\", 0.2, 0.9, step=0.1\n",
        "        ),\n",
        "        #'min_child_samples': trial.suggest_int('min_child_samples', 1, 150),\n",
        "        'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100)\n",
        "    }\n",
        "    olgbm = lgbm.LGBMRegressor(**param)\n",
        "    olgbm.fit(X_train, y_train,eval_set=[(X_test,y_test)], callbacks=[lgbm.early_stopping(100), lgbm.log_evaluation, LightGBMPruningCallback(trial,\"rmse\")])\n",
        "    predictions = olgbm.predict(X_test)\n",
        "    accuracy = mean_squared_error(y_test, predictions)\n",
        "    return accuracy\n",
        "\n",
        "study = optuna.create_study(study_name=\"lightgbm\", direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "model = lgbm.LGBMRegressor(**study.best_params)\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)\n",
        "#model.booster_.save_model(\"OptimizedModel.txt\")\n",
        "#files.download(\"OptimizedModel.txt\")\n",
        "\n",
        "print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
        "print(f\"\\tBest params:\")\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"\\t\\t{key}: {value}\")\n",
        "\n",
        "fig1 = optuna.visualization.plot_optimization_history(study)\n",
        "fig2 = optuna.visualization.plot_slice(study)\n",
        "fig3 = optuna.visualization.plot_param_importances(study)\n",
        "fig1.show()\n",
        "fig2.show()\n",
        "fig3.show()\n",
        "\n",
        "for i in range(len(prediction)):\n",
        "  print(\"Optuna Price: {}\".format(prediction[i]))"
      ]
    }
  ]
}